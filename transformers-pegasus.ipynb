{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998b4acd-e9c0-4b1c-b78a-c0b6f87ddd29",
   "metadata": {},
   "source": [
    "## 评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b41426-78c2-48f3-b7bf-eeefb1bbb64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:27.181991Z",
     "iopub.status.busy": "2023-01-13T08:16:27.181040Z",
     "iopub.status.idle": "2023-01-13T08:16:27.201467Z",
     "shell.execute_reply": "2023-01-13T08:16:27.200989Z",
     "shell.execute_reply.started": "2023-01-13T08:16:27.181815Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.42857142857142855,\n",
       "   'p': 0.5833333333333334,\n",
       "   'f': 0.49411764217577864},\n",
       "  'rouge-2': {'r': 0.18571428571428572,\n",
       "   'p': 0.3170731707317073,\n",
       "   'f': 0.23423422957552154},\n",
       "  'rouge-l': {'r': 0.3877551020408163,\n",
       "   'p': 0.5277777777777778,\n",
       "   'f': 0.44705881864636676}}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "# !pip3.9 install rouge\n",
    "\n",
    "hypothesis = \"the #### transcript is a written version of each day 's cnn student news program use this transcript to he    lp students with reading comprehension and vocabulary use the weekly newsquiz to test your knowledge of storie s you     saw on cnn student news\"\n",
    "\n",
    "reference = \"this page includes the show transcript use the transcript to help students with reading comprehension and     vocabulary at the bottom of the page , comment for a chance to be mentioned on cnn student news . you must be a teac    her or a student age # # or older to request a mention on the cnn student news roll call . the weekly newsquiz tests     students ' knowledge of even ts in the news\"\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hypothesis, reference)\n",
    "\n",
    "scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fad695-dfbe-4b09-8d30-e2ffdf64bd79",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Motivation\n",
    "\n",
    "In our current fast pace society, it is impossible to keep up with the information being generated every single minute.  \n",
    "Even if one limits itself to articles, the volume will still be too much. However, not everything contained in an article is actually relevant.\n",
    "With the abundance of information available, it is therefore neccessary to focus only on relevant information and articles.\n",
    "\n",
    "### Overall goal of the project\n",
    "Our aim is to perform abstractive and extractive text summarization on news articles. This will reduce the time spent on any given article.\n",
    "\n",
    "### What framework are you going to use (Kornia, Transformer, Pytorch-Geometrics)\n",
    "The [Transformers](https://github.com/huggingface/transformers) framework provided by HuggingFace provides high-performance NLP models suitable for a wide range of application - including text summarization.\n",
    "\n",
    "\n",
    "### What data are you going to run on (initially, may change)\n",
    "The [CNN Dailymail](https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail) Dataset contains approximately 300k new articles.\n",
    "Each entry contains the article alongside the summarized article, as well as a unique id.\n",
    "If time allows, we may expand our model by the [XSum dataset and additional articles from Multi-News](https://www.kaggle.com/datasets/sbhatti/news-summarization), available on Kaggle as well.\n",
    "\n",
    "数据集样本个数、不重复单词的个数、原始的文本平均长度、摘要的平均长度、原始文本和摘要的公用单词的比例\n",
    "\n",
    "### What deep learning models do you expect to use\n",
    "Due to both time- and computational constraints, we will refer to pre-trained models, which we intend to fine-tune on the dataset.\n",
    "As the dataset is fairly popular for text summarization, there are several models fitted to it already available. We will use [BigBirdPegasus](https://huggingface.co/docs/transformers/model_doc/bigbird_pegasus) or [Pegasus](https://huggingface.co/docs/transformers/model_doc/pegasus), and might extend using [DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert) or [ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)\n",
    "\n",
    "\n",
    "- 模型的权重大小，文件大小\n",
    "- 模型的精度\n",
    "- 模型的输入的文本最大长度\n",
    "- 四个模型他的原理不同，训练方法（数据构建 + 损失函数）也是不同的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b75d02-c583-4242-9be1-6104436de440",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fdf124-a0fa-4b93-8cab-700283f38c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:27.202498Z",
     "iopub.status.busy": "2023-01-13T08:16:27.202330Z",
     "iopub.status.idle": "2023-01-13T08:16:28.042287Z",
     "shell.execute_reply": "2023-01-13T08:16:28.040969Z",
     "shell.execute_reply.started": "2023-01-13T08:16:27.202482Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# https://www.kaggle.com/datasets/sbhatti/news-summarization\n",
    "data = pd.read_csv('data.csv', nrows=10000)\n",
    "data = data[['Content', 'Summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eddbab3-cca3-472c-bb4b-d7e7ab9b6251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:28.043265Z",
     "iopub.status.busy": "2023-01-13T08:16:28.043135Z",
     "iopub.status.idle": "2023-01-13T08:16:28.050658Z",
     "shell.execute_reply": "2023-01-13T08:16:28.050068Z",
     "shell.execute_reply.started": "2023-01-13T08:16:28.043248Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York police are concerned drones could bec...</td>\n",
       "      <td>Police have investigated criminals who have ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By . Ryan Lipman . Perhaps Australian porn sta...</td>\n",
       "      <td>Porn star Angela White secretly filmed sex act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This was, Sergio Garcia conceded, much like be...</td>\n",
       "      <td>American draws inspiration from fellow country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An Ebola outbreak that began in Guinea four mo...</td>\n",
       "      <td>World Health Organisation: 635 infections and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By . Associated Press and Daily Mail Reporter ...</td>\n",
       "      <td>A sinkhole opened up at 5:15am this morning in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  New York police are concerned drones could bec...   \n",
       "1  By . Ryan Lipman . Perhaps Australian porn sta...   \n",
       "2  This was, Sergio Garcia conceded, much like be...   \n",
       "3  An Ebola outbreak that began in Guinea four mo...   \n",
       "4  By . Associated Press and Daily Mail Reporter ...   \n",
       "\n",
       "                                             Summary  \n",
       "0  Police have investigated criminals who have ri...  \n",
       "1  Porn star Angela White secretly filmed sex act...  \n",
       "2  American draws inspiration from fellow country...  \n",
       "3  World Health Organisation: 635 infections and ...  \n",
       "4  A sinkhole opened up at 5:15am this morning in...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a231333-5adc-43cb-833f-ef065057b571",
   "metadata": {},
   "source": [
    "## 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d43e16-a84a-4b82-88d7-1c4280f8b4db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:28.056515Z",
     "iopub.status.busy": "2023-01-13T08:16:28.056336Z",
     "iopub.status.idle": "2023-01-13T08:16:28.139404Z",
     "shell.execute_reply": "2023-01-13T08:16:28.138206Z",
     "shell.execute_reply.started": "2023-01-13T08:16:28.056498Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99524578-efdb-40e0-be78-75d31a6c21f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:28.142150Z",
     "iopub.status.busy": "2023-01-13T08:16:28.141567Z",
     "iopub.status.idle": "2023-01-13T08:16:35.513877Z",
     "shell.execute_reply": "2023-01-13T08:16:35.513340Z",
     "shell.execute_reply.started": "2023-01-13T08:16:28.142078Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyz/.local/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (5.0.0)/charset_normalizer (2.0.11) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "# transformers 从网站上自动下载权重的词典\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "\n",
    "# 权重文件在本地的路径\n",
    "# tokenizer = PegasusTokenizer.from_pretrained(\"./pegasus-xsum\")\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(\"./pegasus-xsum\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2350cea1-cf4c-45e8-8268-0cc5f8b33124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:35.514877Z",
     "iopub.status.busy": "2023-01-13T08:16:35.514696Z",
     "iopub.status.idle": "2023-01-13T08:16:41.601427Z",
     "shell.execute_reply": "2023-01-13T08:16:41.600692Z",
     "shell.execute_reply.started": "2023-01-13T08:16:35.514854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyz/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3478: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['She worked like crazy and completed 115 hours of community service in Brooklyn to meet her Thursday deadline and avoid jail.'],\n",
       " \"– Tomorrow looks to be a milestone day for Lindsay Lohan: Her lawyer will be able to report to a Los Angeles judge that she has completed all her necessary community service, paving the way for her to be off probation for the first time in seven years, reports TMZ. The community service stems from a reckless driving case, and things looked bleak for Lohan less than three weeks ago when a judge informed her that she still had 115 hours to complete before a May 28 deadline, notes the New York Daily News. Lohan got it done, however, and she's been posting photos of herself on the job at a women's shelter in New York City.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = tokenizer.prepare_seq2seq_batch(data['Content'].iloc[20], \n",
    "                                        truncation=True, \n",
    "                                        padding='longest', \n",
    "                                        return_tensors=\"pt\")\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "# 模型输出的结果 feature map 转换为单词？ 文本的最短长度和最长长度？\n",
    "tgt_text, data['Summary'].iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9cfb776-d689-4925-8207-fbd29587201f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:41.602256Z",
     "iopub.status.busy": "2023-01-13T08:16:41.602127Z",
     "iopub.status.idle": "2023-01-13T08:16:41.607851Z",
     "shell.execute_reply": "2023-01-13T08:16:41.607526Z",
     "shell.execute_reply.started": "2023-01-13T08:16:41.602240Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.5, 'p': 0.11235955056179775, 'f': 0.18348623553572932},\n",
       "  'rouge-2': {'r': 0.1, 'p': 0.017699115044247787, 'f': 0.030075185414664696},\n",
       "  'rouge-l': {'r': 0.45, 'p': 0.10112359550561797, 'f': 0.16513761168251836}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(data['Summary'].iloc[20], tgt_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26216f-ea94-48b5-a503-8548b92e0d85",
   "metadata": {},
   "source": [
    "## 数据集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9754f80c-6587-4c71-9044-3ae95e96a00e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:41.608619Z",
     "iopub.status.busy": "2023-01-13T08:16:41.608439Z",
     "iopub.status.idle": "2023-01-13T08:16:42.299360Z",
     "shell.execute_reply": "2023-01-13T08:16:42.298857Z",
     "shell.execute_reply.started": "2023-01-13T08:16:41.608604Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# 自定义对文本做处理，读取单条记录\n",
    "# 【content， summary】 是一条记录\n",
    "class PegasusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])\n",
    "    \n",
    "# 划分训练集和验证集，5k做训练，1k做验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7466c9-22ef-476b-9727-4234d7704f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:42.300238Z",
     "iopub.status.busy": "2023-01-13T08:16:42.300062Z",
     "iopub.status.idle": "2023-01-13T08:16:42.305770Z",
     "shell.execute_reply": "2023-01-13T08:16:42.305140Z",
     "shell.execute_reply.started": "2023-01-13T08:16:42.300221Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_data(texts, labels):\n",
    "    # content\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=300)\n",
    "    \n",
    "    # summary\n",
    "    decodings = tokenizer(labels, truncation=True, padding=True, max_length=200)\n",
    "    \n",
    "    dataset_tokenized = PegasusDataset(encodings, decodings)\n",
    "    return dataset_tokenized\n",
    "\n",
    "def prepare_data(model_name, \n",
    "                 train_texts, train_labels, \n",
    "                 val_texts=None, val_labels=None, \n",
    "                 test_texts=None, test_labels=None):\n",
    "    \"\"\"\n",
    "    Prepare input data for model fine-tuning\n",
    "    \"\"\"\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "    prepare_val = False if val_texts is None or val_labels is None else True\n",
    "    prepare_test = False if test_texts is None or test_labels is None else True\n",
    "\n",
    "    train_dataset = tokenize_data(train_texts, train_labels)\n",
    "    val_dataset = tokenize_data(val_texts, val_labels) if prepare_val else None\n",
    "    test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a1204-5dda-4734-a80a-4fe5c3bba4c7",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b66946c-8f76-49dc-a36e-39e621aed51a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:42.306594Z",
     "iopub.status.busy": "2023-01-13T08:16:42.306472Z",
     "iopub.status.idle": "2023-01-13T08:16:42.375989Z",
     "shell.execute_reply": "2023-01-13T08:16:42.375008Z",
     "shell.execute_reply.started": "2023-01-13T08:16:42.306580Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset=None, freeze_encoder=False, output_dir='./results'):\n",
    "    \"\"\"\n",
    "    Prepare configurations and base model for fine-tuning\n",
    "    \"\"\"\n",
    "    # torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    torch_device = 'cpu'\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "    \n",
    "    # 四个模型，至少有3类，主要的区别是：模型定义的API 不同、标签的构建API不同\n",
    "    # 不同的模型API不同！\n",
    "    \n",
    "    if freeze_encoder:\n",
    "        for param in model.model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    if val_dataset is not None:\n",
    "        training_args = TrainingArguments(\n",
    "          output_dir=output_dir,           # output directory\n",
    "          num_train_epochs=1,              # total number of training epochs\n",
    "          per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "          per_device_eval_batch_size=1,    # batch size for evaluation, can increase if memory allows\n",
    "          save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "          save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "          evaluation_strategy='steps',     # evaluation strategy to adopt during training\n",
    "          eval_steps=100,                  # number of update steps before evaluation\n",
    "          warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "          weight_decay=0.01,               # strength of weight decay\n",
    "          logging_dir='./logs',            # directory for storing logs\n",
    "          logging_steps=10,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "          model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "          args=training_args,                  # training arguments, defined above\n",
    "          train_dataset=train_dataset,         # training dataset\n",
    "          eval_dataset=val_dataset,            # evaluation dataset\n",
    "          tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        training_args = TrainingArguments(\n",
    "          output_dir=output_dir,           # output directory\n",
    "          num_train_epochs=1,           # total number of training epochs\n",
    "          per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "          save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "          save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "          warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "          weight_decay=0.01,               # strength of weight decay\n",
    "          logging_dir='./logs',            # directory for storing logs\n",
    "          logging_steps=10,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "          model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "          args=training_args,                  # training arguments, defined above\n",
    "          train_dataset=train_dataset,         # training dataset\n",
    "          tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb81df9-2ee4-43ef-bd8b-baed837b485e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:16:42.378657Z",
     "iopub.status.busy": "2023-01-13T08:16:42.378411Z",
     "iopub.status.idle": "2023-01-13T08:22:18.913301Z",
     "shell.execute_reply": "2023-01-13T08:22:18.912882Z",
     "shell.execute_reply.started": "2023-01-13T08:16:42.378641Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyz/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 05:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>9.268200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>9.142200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>10.429500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>9.565900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.849300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>9.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>7.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>9.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>7.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>9.100200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=9.072412796020508, metrics={'train_runtime': 329.3763, 'train_samples_per_second': 0.304, 'train_steps_per_second': 0.304, 'total_flos': 84652277760000.0, 'train_loss': 9.072412796020508, 'epoch': 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts, train_labels = list(data['Content'].iloc[:100]), list(data['Summary'].iloc[:100])\n",
    "\n",
    "# use Pegasus Large model as base for fine-tuning\n",
    "model_name = './pegasus-xsum'\n",
    "\n",
    "train_dataset, _, _, tokenizer = prepare_data(model_name, train_texts, train_labels)\n",
    "\n",
    "trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d9ec5a-644e-4fc3-ab4c-e1cb485d456d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:23:38.707726Z",
     "iopub.status.busy": "2023-01-13T08:23:38.707283Z",
     "iopub.status.idle": "2023-01-13T08:23:40.949595Z",
     "shell.execute_reply": "2023-01-13T08:23:40.949208Z",
     "shell.execute_reply.started": "2023-01-13T08:23:38.707676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results/model.pt\n",
      "Configuration saved in results/model.pt/config.json\n",
      "Model weights saved in results/model.pt/pytorch_model.bin\n",
      "tokenizer config file saved in results/model.pt/tokenizer_config.json\n",
      "Special tokens file saved in results/model.pt/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('results/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd13efef-a95f-4b1d-ba22-ff0396ef648b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:24:03.893450Z",
     "iopub.status.busy": "2023-01-13T08:24:03.892883Z",
     "iopub.status.idle": "2023-01-13T08:24:10.296960Z",
     "shell.execute_reply": "2023-01-13T08:24:10.296571Z",
     "shell.execute_reply.started": "2023-01-13T08:24:03.893401Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file results/model.pt/added_tokens.json. We won't load it.\n",
      "Didn't find file results/model.pt/tokenizer.json. We won't load it.\n",
      "loading file results/model.pt/spiece.model\n",
      "loading file None\n",
      "loading file results/model.pt/special_tokens_map.json\n",
      "loading file results/model.pt/tokenizer_config.json\n",
      "loading file None\n",
      "loading configuration file results/model.pt/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"./pegasus-xsum\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.6,\n",
      "  \"max_length\": 64,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading weights file results/model.pt/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at results/model.pt/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "# tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"results/model.pt/\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"results/model.pt/\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1261f4da-463a-47de-847c-62dc9f52cafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:24:38.793135Z",
     "iopub.status.busy": "2023-01-13T08:24:38.792559Z",
     "iopub.status.idle": "2023-01-13T08:24:42.839440Z",
     "shell.execute_reply": "2023-01-13T08:24:42.839064Z",
     "shell.execute_reply.started": "2023-01-13T08:24:38.793086Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Bordeaux clinched the French league title with a 1-0 win over Caen on a dramatic final day of the season.'],\n",
       " 'Bordeaux beat relegated Caen 1-0 to clinch the French league title .\\nMarseille finish runners-up despite 4-0 home win over Rennes .\\nAtletico Madrid clinch Champions League spot from Primera Liga .\\nBesiktas claim Turkish league title with 2-1 win over Denizlispor .')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = tokenizer.prepare_seq2seq_batch(data['Content'].iloc[50], truncation=True, padding='longest', return_tensors=\"pt\")\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "tgt_text, data['Summary'].iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7509c445-d163-4982-b5cc-af4498eae6b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T08:24:46.714942Z",
     "iopub.status.busy": "2023-01-13T08:24:46.714373Z",
     "iopub.status.idle": "2023-01-13T08:24:46.726162Z",
     "shell.execute_reply": "2023-01-13T08:24:46.725520Z",
     "shell.execute_reply.started": "2023-01-13T08:24:46.714891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.5555555555555556,\n",
       "   'p': 0.29411764705882354,\n",
       "   'f': 0.3846153800887574},\n",
       "  'rouge-2': {'r': 0.2631578947368421,\n",
       "   'p': 0.1388888888888889,\n",
       "   'f': 0.18181817729586788},\n",
       "  'rouge-l': {'r': 0.4444444444444444,\n",
       "   'p': 0.23529411764705882,\n",
       "   'f': 0.30769230316568047}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(data['Summary'].iloc[50], tgt_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06f84b-808a-4b6f-ad82-4abd8c80cba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
